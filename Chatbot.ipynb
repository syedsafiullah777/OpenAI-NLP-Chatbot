{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2fd8a30",
   "metadata": {},
   "source": [
    "# Chatbot"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e909286a",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Now let's start with creating an end-to-end chatbot using Python. I'll start this task by importing the necessary Python libraries for this task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1f646be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/syedsafiullah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "import ssl\n",
    "import streamlit as st\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "nltk.data.path.append(os.path.abspath(\"nltk_data\"))\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c1b4e81",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Now let's define some intents of the chatbot. You can add more intents to make the chatbot more helpful and more functional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d007afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = [\n",
    "    {\n",
    "        \"tag\": \"greeting\",\n",
    "        \"patterns\": [\"Hi\", \"Hello\", \"Hey\", \"How are you\", \"What's up\"],\n",
    "        \"responses\": [\"Hi there\", \"Hello\", \"Hey\", \"I'm fine, thank you\", \"Nothing much\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"goodbye\",\n",
    "        \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\", \"Take care\"],\n",
    "        \"responses\": [\"Goodbye\", \"See you later\", \"Take care\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"thanks\",\n",
    "        \"patterns\": [\"Thank you\", \"Thanks\", \"Thanks a lot\", \"I appreciate it\"],\n",
    "        \"responses\": [\"You're welcome\", \"No problem\", \"Glad I could help\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"about\",\n",
    "        \"patterns\": [\"What can you do\", \"Who are you\", \"What are you\", \"What is your purpose\"],\n",
    "        \"responses\": [\"I am a chatbot\", \"My purpose is to assist you\", \"I can answer questions and provide assistance\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"help\",\n",
    "        \"patterns\": [\"Help\", \"I need help\", \"Can you help me\", \"What should I do\"],\n",
    "        \"responses\": [\"Sure, what do you need help with?\", \"I'm here to help. What's the problem?\", \"How can I assist you?\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"age\",\n",
    "        \"patterns\": [\"How old are you\", \"What's your age\"],\n",
    "        \"responses\": [\"I don't have an age. I'm a chatbot.\", \"I was just born in the digital world.\", \"Age is just a number for me.\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"weather\",\n",
    "        \"patterns\": [\"What's the weather like\", \"How's the weather today\"],\n",
    "        \"responses\": [\"I'm sorry, I cannot provide real-time weather information.\", \"You can check the weather on a weather app or website.\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"budget\",\n",
    "        \"patterns\": [\"How can I make a budget\", \"What's a good budgeting strategy\", \"How do I create a budget\"],\n",
    "        \"responses\": [\"To make a budget, start by tracking your income and expenses. Then, allocate your income towards essential expenses like rent, food, and bills. Next, allocate some of your income towards savings and debt repayment. Finally, allocate the remainder of your income towards discretionary expenses like entertainment and hobbies.\", \"A good budgeting strategy is to use the 50/30/20 rule. This means allocating 50% of your income towards essential expenses, 30% towards discretionary expenses, and 20% towards savings and debt repayment.\", \"To create a budget, start by setting financial goals for yourself. Then, track your income and expenses for a few months to get a sense of where your money is going. Next, create a budget by allocating your income towards essential expenses, savings and debt repayment, and discretionary expenses.\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"credit_score\",\n",
    "        \"patterns\": [\"What is a credit score\", \"How do I check my credit score\", \"How can I improve my credit score\"],\n",
    "        \"responses\": [\"A credit score is a number that represents your creditworthiness. It is based on your credit history and is used by lenders to determine whether or not to lend you money. The higher your credit score, the more likely you are to be approved for credit.\", \"You can check your credit score for free on several websites such as Credit Karma and Credit Sesame.\"]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13cb4a8",
   "metadata": {},
   "source": [
    "\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Load the intents file\n",
    "intents = [\n",
    "    {\n",
    "        \"tag\": \"greeting\",\n",
    "        \"patterns\": [\"Hi\", \"Hello\", \"Hey\", \"How are you\", \"What's up\"],\n",
    "        \"responses\": [\"Hi there\", \"Hello\", \"Hey\", \"I'm fine, thank you\", \"Nothing much\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"goodbye\",\n",
    "        \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\", \"Take care\"],\n",
    "        \"responses\": [\"Goodbye\", \"See you later!\", \"Take care!\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"thanks\",\n",
    "        \"patterns\": [\"Thanks\", \"Thank you\", \"I appreciate it\"],\n",
    "        \"responses\": [\"You're welcome!\", \"No problem!\", \"My pleasure\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Extract patterns and tags\n",
    "X_train = []  # List of patterns (questions)\n",
    "y_train = []  # List of tags (responses)\n",
    "\n",
    "for intent in intents:\n",
    "    for pattern in intent['patterns']:\n",
    "        X_train.append(pattern)\n",
    "        y_train.append(intent['tag'])\n",
    "\n",
    "# Encode labels (tags)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Convert patterns into feature vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Train the model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vectorized, y_train_encoded)\n",
    "\n",
    "# Save the trained model and necessary components\n",
    "joblib.dump(model, './chatbot_model.pkl')\n",
    "joblib.dump(label_encoder, './label_encoder.pkl')\n",
    "joblib.dump(vectorizer, './vectorizer.pkl')\n",
    "\n",
    "print(\"Training complete. Model and components saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277f8c97",
   "metadata": {},
   "source": [
    "#model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the intents file\n",
    "intents = [\n",
    "    {\n",
    "        \"tag\": \"greeting\",\n",
    "        \"patterns\": [\"Hi\", \"Hello\", \"Hey\", \"How are you\", \"What's up\", \"Howdy\", \"Greetings\", \"Good morning\"],\n",
    "        \"responses\": [\"Hi there\", \"Hello\", \"Hey\", \"I'm fine, thank you\", \"Nothing much\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"goodbye\",\n",
    "        \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\", \"Take care\", \"See you soon\", \"Have a nice day\"],\n",
    "        \"responses\": [\"Goodbye\", \"See you later!\", \"Take care!\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"thanks\",\n",
    "        \"patterns\": [\"Thanks\", \"Thank you\", \"I appreciate it\", \"Many thanks\", \"Thanks a lot\"],\n",
    "        \"responses\": [\"You're welcome!\", \"No problem!\", \"My pleasure\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Extract patterns and tags\n",
    "X = []  # List of patterns (questions)\n",
    "y = []  # List of tags (responses)\n",
    "\n",
    "for intent in intents:\n",
    "    for pattern in intent['patterns']:\n",
    "        X.append(pattern)\n",
    "        y.append(intent['tag'])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Encode labels (tags)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert patterns into feature vectors\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=500)\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Train the model using RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_vectorized, y_train_encoded)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "\n",
    "# Print accuracy\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Save the trained model and necessary components\n",
    "joblib.dump(model, './chatbot_model.pkl')\n",
    "joblib.dump(label_encoder, './label_encoder.pkl')\n",
    "joblib.dump(vectorizer, './vectorizer.pkl')\n",
    "\n",
    "print(\"Training complete. Model and components saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9c7a3c",
   "metadata": {},
   "source": [
    "import json\n",
    "import joblib\n",
    "import random  # Importing the random module to fix the error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import openai\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = \"your_openai_api_key_here\"  # Replace with your actual API key\n",
    "\n",
    "# Load the intents file (you can modify this as needed)\n",
    "intents = [\n",
    "    {\n",
    "        \"tag\": \"greeting\",\n",
    "        \"patterns\": [\"Hi\", \"Hello\", \"Hey\", \"How are you\", \"What's up\", \"Howdy\", \"Greetings\", \"Good morning\"],\n",
    "        \"responses\": [\"Hi there\", \"Hello\", \"Hey\", \"I'm fine, thank you\", \"Nothing much\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"goodbye\",\n",
    "        \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\", \"Take care\", \"See you soon\", \"Have a nice day\"],\n",
    "        \"responses\": [\"Goodbye\", \"See you later!\", \"Take care!\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"thanks\",\n",
    "        \"patterns\": [\"Thanks\", \"Thank you\", \"I appreciate it\", \"Many thanks\", \"Thanks a lot\"],\n",
    "        \"responses\": [\"You're welcome!\", \"No problem!\", \"My pleasure\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Extract patterns and tags\n",
    "X = []  # List of patterns (questions)\n",
    "y = []  # List of tags (responses)\n",
    "\n",
    "for intent in intents:\n",
    "    for pattern in intent['patterns']:\n",
    "        X.append(pattern)\n",
    "        y.append(intent['tag'])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Encode labels (tags)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert patterns into feature vectors\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=500)\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Train the model using RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_vectorized, y_train_encoded)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "\n",
    "# Print accuracy\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Save the trained model and necessary components\n",
    "joblib.dump(model, './chatbot_model.pkl')\n",
    "joblib.dump(label_encoder, './label_encoder.pkl')\n",
    "joblib.dump(vectorizer, './vectorizer.pkl')\n",
    "\n",
    "print(\"Training complete. Model and components saved.\")\n",
    "\n",
    "\n",
    "# OpenAI API integration function\n",
    "def get_openai_response(user_input):\n",
    "    try:\n",
    "        # Send request to OpenAI\n",
    "        response = openai.Completion.create(\n",
    "            model=\"text-davinci-003\",  # Change the model if needed\n",
    "            prompt=user_input,\n",
    "            max_tokens=100,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred with OpenAI API: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Chatbot response function using model and OpenAI\n",
    "def chatbot_response(user_input):\n",
    "    # Predict with existing model\n",
    "    input_vectorized = vectorizer.transform([user_input])\n",
    "    prediction = model.predict(input_vectorized)\n",
    "    predicted_tag = label_encoder.inverse_transform(prediction)[0]\n",
    "    \n",
    "    # Get a response based on the predicted tag\n",
    "    for intent in intents:\n",
    "        if intent['tag'] == predicted_tag:\n",
    "            response = random.choice(intent['responses'])\n",
    "            return response\n",
    "    \n",
    "    # If no matching tag, use OpenAI API to generate a response\n",
    "    openai_response = get_openai_response(user_input)\n",
    "    return openai_response if openai_response else \"Sorry, I don't understand.\"\n",
    "\n",
    "\n",
    "# Example usage\n",
    "user_input = \"Hi there\"\n",
    "response = chatbot_response(user_input)\n",
    "print(f\"User: {user_input}\")\n",
    "print(f\"Bot: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f5b0f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 75.00%\n",
      "New model, label encoder, and vectorizer saved to: ./.pkl/\n",
      "Moved vectorizer.pkl to ./.pkl/vectorizer.pkl\n",
      "All .pkl files have been saved and moved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the intents file\n",
    "intents = [\n",
    "    {\n",
    "        \"tag\": \"greeting\",\n",
    "        \"patterns\": [\"Hi\", \"Hello\", \"Hey\", \"How are you\", \"What's up\", \"Howdy\", \"Greetings\", \"Good morning\"],\n",
    "        \"responses\": [\"Hi there!\", \"Hello!\", \"Hey!\", \"I'm here to help you!\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"goodbye\",\n",
    "        \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\", \"Take care\", \"See you soon\", \"Have a nice day\"],\n",
    "        \"responses\": [\"Goodbye!\", \"Take care!\", \"See you later!\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"thanks\",\n",
    "        \"patterns\": [\"Thanks\", \"Thank you\", \"I appreciate it\", \"Many thanks\", \"Thanks a lot\"],\n",
    "        \"responses\": [\"You're welcome!\", \"No problem!\", \"My pleasure!\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Extract patterns and tags\n",
    "X = []  # List of patterns (questions)\n",
    "y = []  # List of tags (responses)\n",
    "\n",
    "for intent in intents:\n",
    "    for pattern in intent['patterns']:\n",
    "        X.append(pattern)\n",
    "        y.append(intent['tag'])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Encode labels (tags)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert patterns into feature vectors\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=500)\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Train the model using RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_vectorized, y_train_encoded)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "\n",
    "# Print accuracy\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Define the directory for saving .pkl files\n",
    "pkl_dir = './.pkl/'  # Using the .pkl folder\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(pkl_dir):\n",
    "    os.makedirs(pkl_dir)\n",
    "\n",
    "# Save the trained model and vectorizer to the specified directory\n",
    "joblib.dump(model, os.path.join(pkl_dir, 'chatbot_model.pkl'))\n",
    "joblib.dump(label_encoder, os.path.join(pkl_dir, 'label_encoder.pkl'))\n",
    "joblib.dump(vectorizer, os.path.join(pkl_dir, 'vectorizer.pkl'))\n",
    "\n",
    "print(\"New model, label encoder, and vectorizer saved to:\", pkl_dir)\n",
    "\n",
    "# Move existing .pkl files if needed\n",
    "existing_files = ['chatbot_model.pkl', 'vectorizer.pkl']\n",
    "\n",
    "for file in existing_files:\n",
    "    if os.path.exists(file):\n",
    "        destination = os.path.join(pkl_dir, file)\n",
    "        os.rename(file, destination)  # Move the file to the new folder\n",
    "        print(f\"Moved {file} to {destination}\")\n",
    "\n",
    "print(\"All .pkl files have been saved and moved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "116f44ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 75.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b27b5252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-05 18:23:41.517 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:41.517 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:41.518 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:41.518 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:41.518 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:41.518 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:41.519 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:41.519 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "# Define the folder path where your .pkl files are saved\n",
    "pkl_folder = './.pkl'  # The folder you saved your .pkl files in\n",
    "\n",
    "# Load your saved model and components from the .pkl folder\n",
    "model_path = os.path.join(pkl_folder, 'chatbot_model.pkl')\n",
    "vectorizer_path = os.path.join(pkl_folder, 'vectorizer.pkl')\n",
    "label_encoder_path = os.path.join(pkl_folder, 'label_encoder.pkl')\n",
    "\n",
    "# Load the files\n",
    "model = joblib.load(model_path)\n",
    "vectorizer = joblib.load(vectorizer_path)\n",
    "label_encoder = joblib.load(label_encoder_path)\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = \"your-api-key\"\n",
    "\n",
    "# Load your intents file\n",
    "intents = [\n",
    "    {\n",
    "        \"tag\": \"greeting\",\n",
    "        \"responses\": [\"Hi there!\", \"Hello!\", \"Hey!\", \"I'm here to help you!\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"goodbye\",\n",
    "        \"responses\": [\"Goodbye!\", \"Take care!\", \"See you later!\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"thanks\",\n",
    "        \"responses\": [\"You're welcome!\", \"No problem!\", \"My pleasure!\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "def get_response_from_intents(user_input):\n",
    "    \"\"\"\n",
    "    Get a response from the intents if the user's input matches.\n",
    "    \"\"\"\n",
    "    input_vectorized = vectorizer.transform([user_input])\n",
    "    predicted_label = model.predict(input_vectorized)[0]\n",
    "    predicted_tag = label_encoder.inverse_transform([predicted_label])[0]\n",
    "\n",
    "    for intent in intents:\n",
    "        if intent['tag'] == predicted_tag:\n",
    "            return intent['responses'][0]  # Return the first response for simplicity\n",
    "\n",
    "    return None\n",
    "\n",
    "def get_response_from_openai(user_input):\n",
    "    \"\"\"\n",
    "    Get a response from OpenAI's GPT model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"text-davinci-003\",  # Use the desired engine\n",
    "            prompt=f\"User: {user_input}\\nChatbot:\",\n",
    "            max_tokens=150,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].text.strip()\n",
    "    except Exception as e:\n",
    "        return \"I'm having trouble connecting to OpenAI. Please try again later.\"\n",
    "\n",
    "def chatbot_response(user_input):\n",
    "    \"\"\"\n",
    "    Combine intent-based responses and OpenAI fallback.\n",
    "    \"\"\"\n",
    "    response = get_response_from_intents(user_input)\n",
    "    if response:\n",
    "        return response\n",
    "    else:\n",
    "        return get_response_from_openai(user_input)\n",
    "\n",
    "# Example: Streamlit integration\n",
    "if __name__ == \"__main__\":\n",
    "    import streamlit as st\n",
    "\n",
    "    st.title(\"Chatbot with OpenAI Integration\")\n",
    "\n",
    "    user_input = st.text_input(\"You: \", \"\")\n",
    "    if user_input:\n",
    "        response = chatbot_response(user_input)\n",
    "        st.text_area(\"Chatbot:\", value=response, height=100, max_chars=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "068665c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-05 18:23:42.240 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:42.241 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:42.241 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:42.241 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:42.242 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:42.242 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:42.242 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:42.243 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "# Define the folder path where your .pkl files are saved\n",
    "pkl_folder = './.pkl'  # Replace with the correct path if necessary\n",
    "\n",
    "# Load your saved model and components from the .pkl folder\n",
    "model_path = os.path.join(pkl_folder, 'chatbot_model.pkl')\n",
    "vectorizer_path = os.path.join(pkl_folder, 'vectorizer.pkl')\n",
    "label_encoder_path = os.path.join(pkl_folder, 'label_encoder.pkl')\n",
    "\n",
    "model = joblib.load(model_path)\n",
    "vectorizer = joblib.load(vectorizer_path)\n",
    "label_encoder = joblib.load(label_encoder_path)\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = \"your-api-key\"\n",
    "\n",
    "# Load your intents file\n",
    "intents = [\n",
    "    {\n",
    "        \"tag\": \"greeting\",\n",
    "        \"responses\": [\"Hi there!\", \"Hello!\", \"Hey!\", \"I'm here to help you!\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"goodbye\",\n",
    "        \"responses\": [\"Goodbye!\", \"Take care!\", \"See you later!\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"thanks\",\n",
    "        \"responses\": [\"You're welcome!\", \"No problem!\", \"My pleasure!\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "def get_response_from_intents(user_input):\n",
    "    \"\"\"\n",
    "    Get a response from the intents if the user's input matches.\n",
    "    \"\"\"\n",
    "    input_vectorized = vectorizer.transform([user_input])\n",
    "    predicted_label = model.predict(input_vectorized)[0]\n",
    "    predicted_tag = label_encoder.inverse_transform([predicted_label])[0]\n",
    "\n",
    "    for intent in intents:\n",
    "        if intent['tag'] == predicted_tag:\n",
    "            return intent['responses'][0]  # Return the first response for simplicity\n",
    "\n",
    "    return None\n",
    "\n",
    "def get_response_from_openai(user_input):\n",
    "    \"\"\"\n",
    "    Get a response from OpenAI's GPT model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"text-davinci-003\",  # Use the desired engine\n",
    "            prompt=f\"User: {user_input}\\nChatbot:\",\n",
    "            max_tokens=150,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].text.strip()\n",
    "    except Exception as e:\n",
    "        return \"I'm having trouble connecting to OpenAI. Please try again later.\"\n",
    "\n",
    "def chatbot_response(user_input):\n",
    "    \"\"\"\n",
    "    Combine intent-based responses and OpenAI fallback.\n",
    "    \"\"\"\n",
    "    response = get_response_from_intents(user_input)\n",
    "    if response:\n",
    "        return response\n",
    "    else:\n",
    "        return get_response_from_openai(user_input)\n",
    "\n",
    "# Example: Streamlit integration\n",
    "if __name__ == \"__main__\":\n",
    "    import streamlit as st\n",
    "\n",
    "    st.title(\"Chatbot with OpenAI Integration\")\n",
    "\n",
    "    user_input = st.text_input(\"You: \", \"\")\n",
    "    if user_input:\n",
    "        response = chatbot_response(user_input)\n",
    "        st.text_area(\"Chatbot:\", value=response, height=100, max_chars=None)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "012bf411",
   "metadata": {},
   "source": [
    "Now let’s prepare the intents and train a Machine Learning model for the chatbot:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0639b5f7",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Now let's write a Python function to chat with the chatbot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3a54112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Model and vectorizer saved.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "# Define the intents with patterns and responses\n",
    "intents = [\n",
    "    {\n",
    "        \"tag\": \"greeting\",\n",
    "        \"patterns\": [\"Hi\", \"Hello\", \"Hey\", \"How are you\", \"What's up\", \"Howdy\", \"Greetings\", \"Good morning\"],\n",
    "        \"responses\": [\"Hi there!\", \"Hello!\", \"Hey!\", \"I'm here to help you!\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"goodbye\",\n",
    "        \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\", \"Take care\", \"See you soon\", \"Have a nice day\"],\n",
    "        \"responses\": [\"Goodbye!\", \"Take care!\", \"See you later!\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"thanks\",\n",
    "        \"patterns\": [\"Thanks\", \"Thank you\", \"I appreciate it\", \"Many thanks\", \"Thanks a lot\"],\n",
    "        \"responses\": [\"You're welcome!\", \"No problem!\", \"My pleasure!\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create the vectorizer and classifier\n",
    "vectorizer = TfidfVectorizer()\n",
    "clf = LogisticRegression(random_state=0, max_iter=10000)\n",
    "\n",
    "# Preprocess the data\n",
    "tags = []\n",
    "patterns = []\n",
    "for intent in intents:\n",
    "    for pattern in intent['patterns']:  # Use the correct 'patterns' key\n",
    "        tags.append(intent['tag'])\n",
    "        patterns.append(pattern)\n",
    "\n",
    "# Training the model\n",
    "x = vectorizer.fit_transform(patterns)  # Convert patterns into feature vectors\n",
    "y = tags  # Labels (tags)\n",
    "clf.fit(x, y)  # Train the model\n",
    "\n",
    "# Save the trained model and vectorizer using joblib\n",
    "joblib.dump(clf, './chatbot_classifier.pkl')\n",
    "joblib.dump(vectorizer, './vectorizer.pkl')\n",
    "\n",
    "print(\"Training complete. Model and vectorizer saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "563685b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(input_text):\n",
    "    input_text = vectorizer.transform([input_text])\n",
    "    tag = clf.predict(input_text)[0]\n",
    "    for intent in intents:\n",
    "        if intent['tag'] == tag:\n",
    "            response = random.choice(intent['responses'])\n",
    "            return response"
   ]
  },
  {
   "cell_type": "raw",
   "id": "471bc8e5",
   "metadata": {},
   "source": [
    "Till now, we have created the chatbot. After running the code, you can interact with the chatbot in the terminal itself. To turn this chatbot into an end-to-end chatbot, we need to deploy it to interact with the chatbot using a user interface. To deploy the chatbot, I will use the streamlit library in Python, which provides amazing features to create a user interface for a Machine Learning application in just a few lines of code."
   ]
  },
  {
   "cell_type": "raw",
   "id": "196a1376",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "So, here's how we can deploy the chatbot using Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "857db1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-05 18:23:48.337 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:48.338 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:48.339 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:48.339 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:48.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:48.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:48.341 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:48.341 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:48.341 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:48.341 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:48.342 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-05 18:23:48.342 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "def main():\n",
    "    global counter\n",
    "    st.title(\"AI-Chatbot\")  # Changed title to \"AI-Chatbot\"\n",
    "    st.write(\"Welcome to the AI-Chatbot. Please type a message and press Enter to start the conversation.\")\n",
    "\n",
    "    counter += 1\n",
    "    user_input = st.text_input(\"You:\", key=f\"user_input_{counter}\")\n",
    "\n",
    "    if user_input:\n",
    "        response = chatbot(user_input)\n",
    "        st.text_area(\"Chatbot:\", value=response, height=100, max_chars=None, key=f\"chatbot_response_{counter}\")\n",
    "\n",
    "        if response.lower() in ['goodbye', 'bye']:\n",
    "            st.write(\"Thank you for chatting with me. Have a great day!\")\n",
    "            st.stop()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa98d6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3a50db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
